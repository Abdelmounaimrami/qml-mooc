{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Annealing at Finite Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Approximate Thermalization\n",
    "Code inspired by the implementation of [QABoM in PyQuil](https://github.com/MichaelBroughton/QABoM/blob/master/qRBM_final.py) by the authors of the paper. [Those slides](https://www.dropbox.com/s/16n5xnqcmsbktfk/LANL_QABoM.pdf?dl=0) by Guillaume Verdon were also particularly useful in understanding the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Boltzmann Machine\n",
    "\n",
    "In a classical Restricted Boltzmann Machine (RBM), the goal is to generate samples from a probability distributition $P(\\textbf{v})$ infered from the data, where $\\textbf{v} \\in \\{0,1\\}^n$. The assumption is that this distribution lies on a latent space that can be paramerized by a set of hidden variables $\\textbf{h} \\in \\{0,1\\}^n$, such that $P(\\textbf{v})=\\sum_hP(\\textbf{v}|\\textbf{h})P(\\textbf{h})$. The joint probability is modeled as a Gibbs distribution with the energy defined by an Ising Model: $P(\\textbf{v}, \\textbf{h})=\\frac{1}{Z} e^{-\\beta E(\\textbf{h},\\textbf{v})}$ where Z is a normalization constant (called partition function) and $E(\\textbf{h},\\textbf{v})=-\\sum_{i,j} W_{ij} h_i v_j$. It can then be shown that $p(\\textbf{h}|\\textbf{v})=\\sigma(W \\cdot \\textbf{v})$ and $p(\\textbf{v}|\\textbf{h})=\\sigma(W \\cdot \\textbf{h})$, where $\\sigma$ is the sigmoid function defined by $\\sigma(x)=\\frac{1}{1+e^{-x}}$.\n",
    "\n",
    "The training procedure consists in finding the weights $W$ that maximizes the log-likelihood $L=\\sum_{\\textbf{v} \\in D} \\log(p(\\textbf{v}|W))$, where $D$ is a set of real observations (dataset). This function is differentiable and can be optimized using regular gradient ascent: $W_{ij}^{(t+1)}=W_{ij}^{(t)} + \\eta \\frac{\\partial L}{\\partial W_{ij}}$. Computing the gradient $\\frac{\\partial L}{\\partial W_{ij}}$ is the hard part. Indeed, one can show that \n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W_{ij}}=\\frac{1}{|D|} \\sum_{\\textbf{v} \\in D} \\mathbb{E}_{\\textbf{h} \\sim P(\\textbf{h}|\\textbf{v})}[h_i v_j] - \\mathbb{E}_{(\\textbf{h},\\textbf{v}) \\sim P(\\textbf{h},\\textbf{v})}[h_i v_j]$$.\n",
    "\n",
    "The first expectancy (under the sum) is easy to compute and can be shown to be equal to $\\sigma \\left( \\sum_j W_{ij} v_j \\right) v_j$. One then just needs to sum those expectancy over the dataset.\n",
    "\n",
    "However, the second expectancy cannot be simplified as easily, since the sum is over all possible $\\textbf{v}$ and $\\textbf{h}$. It would take an exponential amount of time to compute it exactly.\n",
    "\n",
    "Classical RBM uses Monte-Carlo algorithms to approximate this expectancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Boltzmann Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, sampling is a major strength of quantum computers, and it should be possible to approximate the second expectancy with a quantum algorithm. For that, we start by quantizing the RBM model:\n",
    "\n",
    "\\begin{align}\n",
    "E(\\textbf{h},\\textbf{v}) = -\\sum_{i,j} W_{ij} h_i v_j & \\longleftrightarrow H = -\\sum_{<i,j>} W_{ij} \\sigma^Z_i \\sigma^Z_j \\\\\n",
    "P(\\textbf{v}, \\textbf{h})=\\frac{1}{Z} e^{-\\beta E(\\textbf{h},\\textbf{v})} & \\longleftrightarrow \\rho = \\frac{1}{Z} e^{-\\beta H} \\\\\n",
    "& ...\n",
    "\\end{align}\n",
    "\n",
    "Concerning the gradient, the first expectancy only depends on the real data and can still be computed classically. However, the second one can now be computed in a quantum way:\n",
    "\n",
    "$$\\mathbb{E}_{(\\textbf{h},\\textbf{v}) \\sim P(\\textbf{h},\\textbf{v})}[h_i v_j] \\longleftrightarrow \\textrm{tr}\\left[\\rho \\sigma^Z_i \\sigma^Z_j \\right]$$\n",
    "\n",
    "Computing this expectancy then consists in two steps:\n",
    "* Preparing $\\rho$ to approximate the thermal state of $H(W_{ij})$. If we new that the thermal state was a qubit $\\psi$ (which means $\\rho=|\\psi \\rangle \\langle \\psi |$), we could do apply a standard QAOA algorithm, starting from the ground state of $e^{-\\beta H_m}$. The trick here is to purify $\\rho$. If we call $\\mathcal{H_1}$ our current Hilbert space (of dimension $n_{visible} + n_{hidden}$), purifying a density matrix $\\rho$ consists in finding a second Hilbert space $\\mathcal{H_2}$ such that there exists $| \\psi \\rangle \\in \\mathcal{H_1} \\otimes \\mathcal{H_2}$ such that $\\rho = \\textrm{tr}_{\\mathcal{H_2}} \\left( |\\psi \\rangle \\langle \\psi | \\right)$. It can be shown that $| \\psi \\rangle =\\sqrt{2 \\cosh \\beta} \\sum_{z \\in {-1,1}} e^{-\\beta z} |z \\rangle_{\\mathcal{H_1}} \\otimes | z \\rangle_{\\mathcal{H_2}}$ purifies $\\rho=e^{-\\beta H_m}$. This state can be built with a circuit composed uniquely of RX gates and CNOT gates\n",
    "* Tracing over $\\rho \\sigma^Z_i \\sigma^Z_j$ to obtain the expectancy. This can be done using the function `eval` of Qiskit Aqua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\n",
    "from qiskit.wrapper import execute as q_execute\n",
    "from qiskit.tools.qi.pauli import Pauli\n",
    "from qiskit.tools.apps.optimization import eval_hamiltonian \n",
    "from qiskit_aqua.operator import Operator\n",
    "from qiskit_aqua import get_initial_state_instance\n",
    "from qiskit import Aer\n",
    "from qiskit.tools.qi.qi import state_fidelity\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from functools import reduce\n",
    "import itertools\n",
    "\n",
    "from qaoa import QAOA\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a circuit with $n_{visible} + n_{hidden}$ qubits, where the first $n_{visible}$ qubits represent the visible nodes and the $n_{hidden}$ last qubits represent the hidden nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_visible = 2\n",
    "n_hidden = 1\n",
    "n_qubits = n_visible + n_hidden\n",
    "n_system = n_qubits*2 # due to environment qubits, used for purification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta = 1 # inverse temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the weights with a Gaussian distribution of variance $\\frac{2}{n_{hidden} + n_{visible}}$ (the so-called [Xavier initialization](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization), that guarantees good properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_init = np.random.normal(0, 2 / (n_hidden + n_visible), size=(n_visible, n_hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_gamma_nu = 1\n",
    "nu_init = np.random.uniform(0, np.pi*2, n_gamma_nu) # initial nu values\n",
    "gamma_init = np.random.uniform(0, np.pi*2, n_gamma_nu) # initial gamma values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Very simple dataset, same as in the original code. Rows are samples and columns features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = np.array([[1,1,-1,-1], [1,1,-1,-1], [-1,-1,1,1], [-1,-1,1,1]])\n",
    "X_train = np.array([[-1, 1], [1,-1], [-1,1], [1,-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the hamiltonians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pauli_z(qubit, coeff):\n",
    "    eye = np.eye((n_system))\n",
    "    return Operator([[coeff, Pauli(eye[qubit], np.zeros(n_system))]])\n",
    "\n",
    "def pauli_x(qubit, coeff):\n",
    "    eye = np.eye((n_system))\n",
    "    return Operator([[1, Pauli(np.zeros(n_system), eye[qubit])]])\n",
    "\n",
    "def product_pauli_z(q1, q2, coeff):\n",
    "    eye = np.eye((n_system))\n",
    "    return Operator([[coeff, Pauli(eye[q1], np.zeros(n_system)) * Pauli(eye[q2], np.zeros(n_system))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixer hamiltonian\n",
    "Reference hamiltonian for QAOA, defined by $H_m = \\sum_i^n \\sigma^X_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hm = reduce(lambda x,y:x+y,\n",
    "            [pauli_x(i, 1) \n",
    "             for i in range(n_qubits)])\n",
    "Hm.to_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost hamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ising_hamiltonian(weights):\n",
    "    H = reduce(lambda x,y:x+y,\n",
    "            [product_pauli_z(i,n_visible + j, -weights[i,j]) # J[i,j] as a first parameter\n",
    "             for i,j in itertools.product(range(n_visible), range(n_hidden))])\n",
    "    H.to_matrix()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial state preparation\n",
    "We prepare the intial state $|\\psi_0 \\rangle = \\sqrt{2 cosh(\\beta)} \\sum_{z \\in {1, -1}} e^{-\\beta z} | z \\rangle_S \\otimes | z \\rangle_E$, with $E$ a temporary space used for purification purpose. It can be shown that tracing out this state over $E$ reproduces the state $\\rho \\propto e^{-\\beta H_m} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qr = QuantumRegister(n_qubits * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_init = QuantumCircuit(qr)\n",
    "\n",
    "alpha = 2 * np.arctan(np.exp(- beta / 2))\n",
    "for i in range(n_qubits):\n",
    "    circuit_init.rx(alpha, qr[n_qubits+i])\n",
    "    circuit_init.cx(qr[n_qubits+i], qr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_thermalized_state(weights, maxiter):\n",
    "    Hc = ising_hamiltonian(weights)\n",
    "    print(\"Begin QAOA...\")\n",
    "    qaoa = QAOA(mixer_hamiltonian=Hm,\n",
    "                cost_hamiltonian=Hc,\n",
    "                quantum_register=qr,\n",
    "                circuit_init=circuit_init,\n",
    "                n_gamma_nu=n_gamma_nu)\n",
    "    \n",
    "    circuit, result = qaoa.optimize(maxiter=maxiter)\n",
    "    print(\"Results of QAOA\", result)\n",
    "    \n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_hamiltonian(hamiltonian, circuit):\n",
    "    return np.real(hamiltonian.eval(\"matrix\", circuit, 'statevector_simulator')[0]) # the value should always be real in theory, but for numerical reasons the imaginary part can be a very small number\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hidden_units(visible):\n",
    "    return sigmoid(np.dot(visible, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "circuit = circuit_init\n",
    "weights = weights_init.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin QAOA...\n",
      "test\n",
      "test_fin\n",
      "test\n",
      "test_fin\n",
      "test\n",
      "test_fin\n",
      "test\n",
      "test_fin\n",
      "test\n",
      "test_fin\n",
      "Results of QAOA  final_simplex: (array([[2.74, 5.6 ],\n",
      "       [2.61, 5.89],\n",
      "       [2.74, 5.89]]), array([0.01, 0.07, 0.07]))\n",
      "           fun: 0.005704832557674188\n",
      "       message: 'Maximum number of iterations has been exceeded.'\n",
      "          nfev: 5\n",
      "           nit: 2\n",
      "        status: 2\n",
      "       success: False\n",
      "             x: array([2.74, 5.6 ])\n",
      "Begin QAOA...\n",
      "test\n",
      "test_fin\n",
      "test\n",
      "test_fin\n",
      "test\n",
      "test_fin\n",
      "test\n",
      "test_fin\n",
      "test\n",
      "test_fin\n",
      "Results of QAOA  final_simplex: (array([[0.07, 3.94],\n",
      "       [0.07, 3.84],\n",
      "       [0.07, 3.84]]), array([9.93e-05, 4.09e-03, 4.09e-03]))\n",
      "           fun: 9.93252125969903e-05\n",
      "       message: 'Maximum number of iterations has been exceeded.'\n",
      "          nfev: 5\n",
      "           nit: 2\n",
      "        status: 2\n",
      "       success: False\n",
      "             x: array([0.07, 3.94])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    thermalized_state = get_thermalized_state(weights, maxiter=2)\n",
    "    \n",
    "    delta_2 = np.zeros((n_visible, n_hidden))\n",
    "    for v in range(n_visible):\n",
    "        for h in range(n_hidden):\n",
    "            delta_2 = evaluate_hamiltonian(pauli_z(v, 1) * pauli_z(h, 1), thermalized_state)\n",
    "            \n",
    "    hidden_probs = sigmoid(np.dot(X_train, weights))\n",
    "    delta_1 = np.dot(X_train.T, hidden_probs) / len(X_train)\n",
    "    \n",
    "    weights += lr * (delta_1 - delta_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "If the training worked, we should have $P(\\textbf{h}|\\textbf{v}) \\sim 1$ for $\\textbf{v}\\in D$. Let's try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hidden_units(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
